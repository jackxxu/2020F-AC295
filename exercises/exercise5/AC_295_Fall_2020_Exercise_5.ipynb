{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNoQXuvWxiOZ"
   },
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> APCOMP 295 Advanced Practical Data Science\n",
    "## Exercise 5: Semantic Segmentation with Transfer Learning\n",
    "\n",
    "\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2020**<br/>\n",
    "**Instructors**: Pavlos Protopapas\n",
    "\n",
    "\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mriVkeegT73f"
   },
   "source": [
    "**Each assignment is graded out of 5 points.  The topic for this assignment is Semantic Segmentation with Transfer Learning.**\n",
    "\n",
    "**Due:** 10/20/2020 10:15 AM EDT\n",
    "\n",
    "**Submit:** We won't be re running your notebooks, please ensure output is visible in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPodCwOvUDfb"
   },
   "source": [
    "#### Learning Objectives\n",
    "\n",
    "In this exercise you will cover the following topics:  \n",
    "- Building data input pipelines using `tf.data`\n",
    "- Build Semantic Segmentation model with a pretrained image classifier as base\n",
    "- Using callbacks to manage model training paramaters\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQLt2wsm9mTu"
   },
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import shutil\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from string import Template\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from keras.utils.layer_utils import count_params\n",
    "\n",
    "from google.colab import auth\n",
    "from google.cloud import storage\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qe5ijFq99t7Q"
   },
   "source": [
    "#### Verify Setup\n",
    "\n",
    "It is a good practice to verify what version of TensorFlow & Keras you are using. Also verify if GPU is enabled and what GPU you have. Run the following cells and record the version of TensorFlow\n",
    "\n",
    "References:\n",
    "- [Eager Execution](https://www.tensorflow.org/guide/eager)\n",
    "- [Data Performance](https://www.tensorflow.org/guide/data_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wapw5G0W9xuP"
   },
   "outputs": [],
   "source": [
    "# Enable/Disable Eager Execution\n",
    "# Reference: https://www.tensorflow.org/guide/eager\n",
    "# TensorFlow's eager execution is an imperative programming environment that evaluates operations immediately, \n",
    "# without building graphs\n",
    "\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "#tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "print(\"tensorflow version\", tf.__version__)\n",
    "print(\"keras version\", tf.keras.__version__)\n",
    "print(\"Eager Execution Enabled:\", tf.executing_eagerly())\n",
    "\n",
    "# Get the number of replicas \n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"Number of replicas:\", strategy.num_replicas_in_sync)\n",
    "\n",
    "devices = tf.config.experimental.get_visible_devices()\n",
    "print(\"Devices:\", devices)\n",
    "print(tf.config.experimental.list_logical_devices('GPU'))\n",
    "\n",
    "print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n",
    "print(\"All Physical Devices\", tf.config.list_physical_devices())\n",
    "\n",
    "# Better performance with the tf.data API\n",
    "# Reference: https://www.tensorflow.org/guide/data_performance\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-l42DqYzh74T"
   },
   "source": [
    "Run this cell to see what GPU you have. If you get a P100 or T4 GPU that's great. If it's K80, it will still work but it will be slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G2Zk0ps7h-iO"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xTT0Z2iiQY-"
   },
   "source": [
    "#### Utils\n",
    "\n",
    "Here are some util functions that will be helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hqEuSYraiRcN"
   },
   "outputs": [],
   "source": [
    "def download_file(packet_url, base_path=\"\", extract=False):\n",
    "  if base_path != \"\":\n",
    "    if not os.path.exists(base_path):\n",
    "      os.mkdir(base_path)\n",
    "  packet_file = os.path.basename(packet_url)\n",
    "  with requests.get(packet_url, stream=True) as r:\n",
    "      r.raise_for_status()\n",
    "      with open(os.path.join(base_path,packet_file), 'wb') as f:\n",
    "          for chunk in r.iter_content(chunk_size=8192):\n",
    "              f.write(chunk)\n",
    "  \n",
    "  if extract:\n",
    "    with zipfile.ZipFile(os.path.join(base_path,packet_file)) as zfile:\n",
    "        zfile.extractall(base_path)\n",
    "\n",
    "class JsonEncoder(json.JSONEncoder):\n",
    "  def default(self, obj):\n",
    "    if isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, decimal.Decimal):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    else:\n",
    "        return super(JsonEncoder, self).default(obj)\n",
    "\n",
    "def save_model(path=\"models\",model_name=\"model01\"):\n",
    "\n",
    "  # Ensure path exists\n",
    "  if not os.path.exists(path):\n",
    "      os.mkdir(path)\n",
    "\n",
    "  # Save the enitire model (structure + weights)\n",
    "  model.save(os.path.join(path,model_name+\".hdf5\"))\n",
    "\n",
    "  # Save only the weights\n",
    "  model.save_weights(os.path.join(path,model_name+\".h5\"))\n",
    "\n",
    "  # Save the structure only\n",
    "  model_json = model.to_json()\n",
    "  with open(os.path.join(path,model_name+\".json\"), \"w\") as json_file:\n",
    "      json_file.write(model_json)\n",
    "\n",
    "def get_model_size(path=\"models\",model_name=\"model01\"):\n",
    "  model_size = os.stat(os.path.join(path,model_name+\".hdf5\")).st_size\n",
    "  return model_size\n",
    "\n",
    "def evaluate_save_model(model,test_data, training_results,execution_time, learning_rate, batch_size, epochs, optimizer,save=True):\n",
    "    \n",
    "  # Get the model train history\n",
    "  model_train_history = training_results.history\n",
    "  # Get the number of epochs the training was run for\n",
    "  num_epochs = len(model_train_history[\"loss\"])\n",
    "\n",
    "  # Plot training results\n",
    "  fig = plt.figure(figsize=(15,5))\n",
    "  axs = fig.add_subplot(1,2,1)\n",
    "  axs.set_title('Loss')\n",
    "  # Plot all metrics\n",
    "  for metric in [\"loss\",\"val_loss\"]:\n",
    "      axs.plot(np.arange(0, num_epochs), model_train_history[metric], label=metric)\n",
    "  axs.legend()\n",
    "  \n",
    "  axs = fig.add_subplot(1,2,2)\n",
    "  axs.set_title('Accuracy')\n",
    "  # Plot all metrics\n",
    "  for metric in [\"accuracy\",\"val_accuracy\"]:\n",
    "      axs.plot(np.arange(0, num_epochs), model_train_history[metric], label=metric)\n",
    "  axs.legend()\n",
    "\n",
    "  plt.show()\n",
    "  \n",
    "  # Evaluate on test data\n",
    "  evaluation_results = model.evaluate(test_data)\n",
    "  print(evaluation_results)\n",
    "  \n",
    "  if save:\n",
    "      # Save model\n",
    "      save_model(model_name=model.name)\n",
    "      model_size = get_model_size(model_name=model.name)\n",
    "\n",
    "      # Save model history\n",
    "      with open(os.path.join(\"models\",model.name+\"_train_history.json\"), \"w\") as json_file:\n",
    "          json_file.write(json.dumps(model_train_history,cls=JsonEncoder))\n",
    "\n",
    "      trainable_parameters = count_params(model.trainable_weights)\n",
    "      non_trainable_parameters = count_params(model.non_trainable_weights)\n",
    "\n",
    "      # Save model metrics\n",
    "      metrics ={\n",
    "          \"trainable_parameters\":trainable_parameters,\n",
    "          \"execution_time\":execution_time,\n",
    "          \"loss\":evaluation_results[0],\n",
    "          \"accuracy\":evaluation_results[1],\n",
    "          \"model_size\":model_size,\n",
    "          \"learning_rate\":learning_rate,\n",
    "          \"batch_size\":batch_size,\n",
    "          \"epochs\":epochs,\n",
    "          \"optimizer\":type(optimizer).__name__,\n",
    "          \"label_names\": label_names,\n",
    "          \"name\": model.name,\n",
    "          \"id\": int(time.time())\n",
    "      }\n",
    "      with open(os.path.join(\"models\",model.name+\"_metrics.json\"), \"w\") as json_file:\n",
    "          json_file.write(json.dumps(metrics,cls=JsonEncoder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qv-3tA1dUOg_"
   },
   "source": [
    "## Question 1 : Setup & Concepts (1.0 Point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GFTfRMONUZDg"
   },
   "source": [
    "#### a) Explain in your own words the difference between image classification and semantic segmentation\n",
    "\n",
    "Needs to be 2-3 sentences at most.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fjffCkLIUZts"
   },
   "source": [
    "##### **Submission:** \n",
    "\n",
    "*your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "txOAIjJwXiFG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCKsQzZmUfSI"
   },
   "source": [
    "#### b) How is this difference reflected in the architecture of the neural network used for either classification and segmentation ?\n",
    "\n",
    "what is the shape of the last layer for each?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPj3P1cSUfxd"
   },
   "source": [
    "##### **Submission:** \n",
    "\n",
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jy4Gtk1xipWV"
   },
   "source": [
    "## Download & Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Tru1l16itmO"
   },
   "source": [
    "#### Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kK3wPOeJip3a"
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "download_file(\"https://github.com/shivasj/dataset-store/releases/download/v2.0/pascal_voc2012_subset.zip\", base_path=\"datasets\", extract=True)\n",
    "execution_time = (time.time() - start_time)/60.0\n",
    "print(\"Download execution time (mins)\",execution_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kr1Ae6QQi60h"
   },
   "source": [
    "#### Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82eYJM2Ci8om"
   },
   "outputs": [],
   "source": [
    "label_names = ['background', 'aeroplane', 'car', 'cat', 'dog', 'person']\n",
    "# Number of unique labels\n",
    "num_classes = len(label_names) \n",
    "# Create label index for easy lookup\n",
    "label2index = dict((name, index) for index, name in enumerate(label_names))\n",
    "index2label = dict((index, name) for index, name in enumerate(label_names))\n",
    "\n",
    "# Input Images\n",
    "data_x = glob('datasets/inputs/*.jpg')\n",
    "print(\"Dataset count:\",len(data_x))\n",
    "print(data_x[:5])\n",
    "\n",
    "# Output masks\n",
    "data_y = [x.replace(\"inputs\",\"outputs\").replace(\"jpg\",\"png\") for x in data_x]\n",
    "print(\"Mask files count:\",len(data_y))\n",
    "print(data_y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6PCkbAv06Bk"
   },
   "source": [
    "#### View Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "91EbPdijjE0Y"
   },
   "outputs": [],
   "source": [
    "# Generate a random sample of index\n",
    "image_samples = np.random.randint(0,high=len(data_x)-1, size=4)\n",
    "\n",
    "fig = plt.figure(figsize=(20,8))\n",
    "for i,img_idx in enumerate(image_samples):\n",
    "  axs = fig.add_subplot(2,4,i+1)\n",
    "  # Read image\n",
    "  sample_input = cv2.imread(data_x[img_idx])\n",
    "  plt.imshow(cv2.cvtColor(sample_input, cv2.COLOR_BGR2RGB))\n",
    "  plt.axis('off')\n",
    "\n",
    "  sample_mask = cv2.imread(data_y[img_idx])\n",
    "  sample_mask = sample_mask[:,:,0]\n",
    "  print(\"Mask Shape:\",sample_mask.shape,\"Classes:\",np.unique(sample_mask))\n",
    "  axs = fig.add_subplot(2,4,i+1+4)\n",
    "  plt.imshow(sample_mask)\n",
    "  plt.axis('off')\n",
    "\n",
    "  title = \"\"\n",
    "  for cls in np.unique(sample_mask):\n",
    "    if cls > 0:\n",
    "      title = title + index2label[cls] +\", \"\n",
    "  axs.set_title(title)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C1dzqHYbjJNv"
   },
   "outputs": [],
   "source": [
    "# Find class counts\n",
    "class_counts = dict((index, 0) for index, name in enumerate(label_names))\n",
    "\n",
    "for y in data_y:\n",
    "  mask = cv2.imread(y)\n",
    "  mask = mask[:,:,0]\n",
    "  for cls in np.unique(mask):\n",
    "    class_counts[cls] = class_counts[cls] +1\n",
    "\n",
    "print(\"Labels:\", label2index)\n",
    "print(\"Class Counts:\",class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yr_MRb6sUsEO"
   },
   "source": [
    "#### c) Explain how the data for the mask files are stored \n",
    "\n",
    "Hint: Analyze the content of `outputs` folder in your dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXWtgfZOUx7M"
   },
   "source": [
    "##### **Submission:** \n",
    "\n",
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffOUXUv9jMi0"
   },
   "source": [
    "#### Build Data Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "83h0AZTAjNBk"
   },
   "outputs": [],
   "source": [
    "validation_percent = 0.15\n",
    "\n",
    "# Split data into train / validate\n",
    "train_x, validate_x, train_y, validate_y = train_test_split(data_x, data_y, test_size=validation_percent)\n",
    "\n",
    "print(\"train_x count:\",len(train_x))\n",
    "print(\"validate_x count:\",len(validate_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nK402mBKjT9E"
   },
   "outputs": [],
   "source": [
    "image_width = 224\n",
    "image_height = 224\n",
    "num_channels = 3\n",
    "num_output_masks = num_classes\n",
    "batch_size = 4\n",
    "train_buffer_size=800\n",
    "validation_buffer_size=200\n",
    "\n",
    "# Load Image\n",
    "def load_image(input_path, mask_path):\n",
    "  # Input image\n",
    "  input_image = tf.io.read_file(input_path)\n",
    "  input_image = tf.image.decode_jpeg(input_image, channels=num_channels)\n",
    "  \n",
    "  # Mask image\n",
    "  mask_image = tf.io.read_file(mask_path)\n",
    "  mask_image = tf.image.decode_png(mask_image, channels=1)\n",
    "\n",
    "  # Random cropping\n",
    "  crop_x = np.random.randint(256 - image_width)\n",
    "  crop_y = np.random.randint(256 - image_height)\n",
    "  input_image = input_image[crop_y:crop_y+image_height, crop_x:crop_x+image_width]\n",
    "  mask_image = mask_image[crop_y:crop_y+image_height, crop_x:crop_x+image_width]\n",
    "  mask_image = tf.cast(mask_image, tf.float32)\n",
    "\n",
    "  # Random Flipping\n",
    "  if tf.random.uniform(()) > 0.5:\n",
    "    input_image = tf.image.flip_left_right(input_image)\n",
    "    mask_image = tf.image.flip_left_right(mask_image)\n",
    "  \n",
    "  return input_image, mask_image\n",
    "\n",
    "# Scale pixels\n",
    "def scale_image_pixels(input_image, mask_image):\n",
    "  input_image = tf.cast(input_image, tf.float32)\n",
    "  input_image = input_image/127.5\n",
    "  input_image -= 1.\n",
    "  return input_image, mask_image\n",
    "\n",
    "# Create TF Dataset\n",
    "train_data = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
    "validation_data = tf.data.Dataset.from_tensor_slices((validate_x, validate_y))\n",
    "\n",
    "#############\n",
    "# Train data\n",
    "#############\n",
    "# Apply all data processing logic\n",
    "train_data = train_data.map(load_image, num_parallel_calls=AUTOTUNE)\n",
    "train_data = train_data.map(scale_image_pixels, num_parallel_calls=AUTOTUNE)\n",
    "train_data = train_data.shuffle(buffer_size=train_buffer_size)\n",
    "train_data = train_data.batch(batch_size)\n",
    "\n",
    "##################\n",
    "# Validation data\n",
    "##################\n",
    "# Apply all data processing logic\n",
    "validation_data = validation_data.map(load_image, num_parallel_calls=AUTOTUNE)\n",
    "validation_data = validation_data.map(scale_image_pixels, num_parallel_calls=AUTOTUNE)\n",
    "validation_data = validation_data.shuffle(buffer_size=validation_buffer_size)\n",
    "validation_data = validation_data.batch(batch_size)\n",
    "\n",
    "print(\"train_data\",train_data)\n",
    "print(\"validation_data\",validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cbh-1dNiU7GI"
   },
   "source": [
    "---\n",
    "\n",
    "## Question 2 : Train Semantic Segmentation Model from Scratch (1.5 Point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wAvGE8uPVK6L"
   },
   "source": [
    "#### a) Train a model without transfer learning\n",
    "\n",
    "- Build a Semantic Segmentation Model. Ensure that the model is built without transfer learning.\n",
    "- Ensure there is a plot of your training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qjAs5ZrQjbnL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GQJzwTAVXAZ"
   },
   "source": [
    "#### b) View results from model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31-5tzbA59pA"
   },
   "source": [
    "## View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZJvoAN126Ang"
   },
   "outputs": [],
   "source": [
    "cmap_ref = cm.get_cmap('tab20', 12)\n",
    "cmap_seg = np.zeros((6, 4))\n",
    "cmap_seg[0] = [0.7, 0.7, 0.7, 0]\n",
    "for i in range(1, 6):\n",
    "  cmap_seg[i] = cmap_ref(i)\n",
    "\n",
    "cmap_seg = ListedColormap(cmap_seg)\n",
    "print(\"\\nClasses to detect, with corresponding colors:\")\n",
    "plt.imshow([[0, 1, 2, 3, 4, 5]], cmap=cmap_seg)\n",
    "plt.xticks([0,1 ,2 ,3 ,4 ,5, 6], label_names, rotation=45)\n",
    "plt.show()\n",
    "\n",
    "def preprocess_prediction_image(file_path):\n",
    "  # Read image\n",
    "  image = cv2.imread(file_path)\n",
    "  # convert to rgb\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "  # Reshape\n",
    "  #image = cv2.resize(image, (image_height, image_width), interpolation=cv2.INTER_AREA)\n",
    "  crop_x = (image.shape[1] - image_width) // 2\n",
    "  crop_y = (image.shape[0] - image_height) // 2\n",
    "  image = image[crop_y:crop_y+image_height, crop_x:crop_x+image_width]\n",
    "  # Scale pixel\n",
    "  image = image.astype(np.float32)\n",
    "  image /= 127.5\n",
    "  image -= 1.\n",
    "\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oCCmjAhQnPBf"
   },
   "outputs": [],
   "source": [
    "# Generate a random sample of index\n",
    "image_samples = np.random.randint(0,high=len(validate_x)-1, size=4)\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "for i,img_idx in enumerate(image_samples):\n",
    "  axs = fig.add_subplot(3,4,i+1)\n",
    "  # Read image\n",
    "  sample_input = cv2.imread(validate_x[img_idx])\n",
    "  plt.imshow(cv2.cvtColor(sample_input, cv2.COLOR_BGR2RGB))\n",
    "  plt.axis('off')\n",
    "  axs.set_title(\"Image\")\n",
    "\n",
    "  sample_mask = cv2.imread(validate_y[img_idx])\n",
    "  sample_mask = sample_mask[:,:,0]\n",
    "  axs = fig.add_subplot(3,4,i+1+4)\n",
    "  plt.imshow(sample_mask)\n",
    "  plt.axis('off')\n",
    "  axs.set_title(\"Masks\")\n",
    "\n",
    "  axs = fig.add_subplot(3,4,i+1+8)\n",
    "  plt.imshow(cv2.cvtColor(sample_input, cv2.COLOR_BGR2RGB))\n",
    "  plt.axis('off')\n",
    "\n",
    "  predict_x = [preprocess_prediction_image(validate_x[img_idx])]\n",
    "  predict_x = np.asarray(predict_x)\n",
    "  # Make predictions\n",
    "  predictions = model.predict(predict_x)\n",
    "\n",
    "  sample_pred = predictions[0]\n",
    "  # Generate mask outputs\n",
    "  pred_mask = tf.argmax(sample_pred, axis=-1)\n",
    "  plt.imshow(pred_mask, cmap=cmap_seg, vmin=0, vmax=num_output_masks, alpha=0.6)\n",
    "\n",
    "  title = \"\"\n",
    "  for cls in np.unique(pred_mask):\n",
    "    if cls > 0:\n",
    "      title = title + index2label[cls] +\", \"\n",
    "  axs.set_title(title)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMWLOPrrVbGl"
   },
   "source": [
    "#### c) Explain why this model is performing poorly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__s_cal1VehO"
   },
   "source": [
    "##### **Submission:** \n",
    "\n",
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Tw6Z_1uVgzT"
   },
   "source": [
    "---\n",
    "\n",
    "## Question 3 : Train Semantic Segmentation Model with Transfer Learning (2.5 Point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8RkMLOLVkE7"
   },
   "source": [
    "#### a) Train model with transfer learning\n",
    "\n",
    "- Build a Semantic Segmentation Model but this time with transfer learning.\n",
    "- Ensure there is a plot of your training history\n",
    "- Your baseline loss for the models should be a **Validation Loss** less than 0.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oASX6tN1V2L1"
   },
   "source": [
    "#### b) View results from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KIZObceUV6tn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djiIMiDRV67K"
   },
   "source": [
    "#### c) Explain why this model is doing a \"good job\" on semantic segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqerVCAYV7yZ"
   },
   "source": [
    "##### **Submission:** \n",
    "\n",
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYdchFHrWLHQ"
   },
   "source": [
    "#### d) Improve model performance\n",
    "\n",
    "The dataset is small for this problem and there are a few techniques you could use to further improve model performance. Try a few from this list to see if you can lower your validation loss:\n",
    "- Change Optimizer, learning rate, loss function etc.\n",
    "- Using a Learning rate scheduler\n",
    "- Using Early Stopping to stop training\n",
    "- Add more data augmentation\n",
    "- Or any other parameter or metric that works for you\n",
    "\n",
    "What was the lowest validation loss you were able to achieve? And what techniques did you use and what helped and what did not? (2-3 sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ltuRrBgwWRWi"
   },
   "source": [
    "##### **Submission:** \n",
    "*your answer here*"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "QQLt2wsm9mTu",
    "qe5ijFq99t7Q",
    "4xTT0Z2iiQY-"
   ],
   "name": "AC 295 Fall 2020 Exercise 5.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
